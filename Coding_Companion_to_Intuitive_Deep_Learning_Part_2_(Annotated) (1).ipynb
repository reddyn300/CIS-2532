{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Student: Nikhil Reddy\n",
        "# Original Author: Joseph Lee (GitHub: josephlee94)\n",
        "# Modified for assignment purposes."
      ],
      "metadata": {
        "id": "JcLcZaRLs7d4"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-pSQ8pzpc9vz"
      },
      "source": [
        "# Coding Companion for Intuitive Deep Learning Part 2 (Annotated)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nguqvRruc9v0"
      },
      "source": [
        "The medium post for this notebook is [here](https://medium.com/@josephleeweien/build-your-first-convolutional-neural-network-to-recognize-images-84b9c78fe0ce).\n",
        "\n",
        "In this notebook, we'll go through the code for the coding companion for [Intuitive Deep Learning Part 2](https://medium.com/intuitive-deep-learning/intuitive-deep-learning-part-2-cnns-for-computer-vision-24992d050a27) to create your very first Convolutional neural network to predict what is contained within the image (airplane, automobile, bird, cat, deer, dog, frog, horse, ship, and truck). We will go through the following in this notebook:\n",
        "\n",
        "- Exploring and Processing the Data\n",
        "- Building and Training our Convolutional Neural Network\n",
        "- Testing out with your own images\n",
        "\n",
        "Note that the results you get might differ slightly from the blogpost as there is a degree of randomness in the way we split our dataset as well as the initialization of our neural network."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kZ4cyeaIc9v0"
      },
      "source": [
        "# Exploring and Processing the Data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JauAVH4dc9v1"
      },
      "source": [
        "We will first have to download our dataset, CIFAR-10. The details of the dataset are as follows:\n",
        "- Images to be recognized: Tiny images of 32 * 32 pixels\n",
        "- Labels: 10 possible labels (airplane, automobile, bird, cat, deer, dog, frog, horse, ship, and truck)\n",
        "- Dataset size: 60000 images, split into 50000 for training and 10000 for testing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U1hGzn9ac9v1",
        "outputId": "62368a49-6ca5-45d7-f77b-d753d7ed8c31"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n",
            "\u001b[1m170498071/170498071\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 0us/step\n"
          ]
        }
      ],
      "source": [
        "from keras.datasets import cifar10\n",
        "(x_train, y_train), (x_test, y_test) = cifar10.load_data()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VnQOduQ8c9v2",
        "outputId": "c05bae4f-4482-44ec-ead1-09dd695388ff"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "x_train shape: (50000, 32, 32, 3)\n"
          ]
        }
      ],
      "source": [
        "print('x_train shape:', x_train.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lAtdhKGxc9v2",
        "outputId": "b73c2811-e523-48f4-95f8-2901d7180982"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "y_train shape: (50000, 1)\n"
          ]
        }
      ],
      "source": [
        "print('y_train shape:', y_train.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BjlTPr9sc9v2"
      },
      "source": [
        "We will now take a look at an individual image. If we print out the first image of our training dataset (x_train[0]):"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hG-Q3yM6c9v2",
        "outputId": "994a7957-fe35-4a24-c2d7-8293283f04dd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[[ 59  62  63]\n",
            "  [ 43  46  45]\n",
            "  [ 50  48  43]\n",
            "  ...\n",
            "  [158 132 108]\n",
            "  [152 125 102]\n",
            "  [148 124 103]]\n",
            "\n",
            " [[ 16  20  20]\n",
            "  [  0   0   0]\n",
            "  [ 18   8   0]\n",
            "  ...\n",
            "  [123  88  55]\n",
            "  [119  83  50]\n",
            "  [122  87  57]]\n",
            "\n",
            " [[ 25  24  21]\n",
            "  [ 16   7   0]\n",
            "  [ 49  27   8]\n",
            "  ...\n",
            "  [118  84  50]\n",
            "  [120  84  50]\n",
            "  [109  73  42]]\n",
            "\n",
            " ...\n",
            "\n",
            " [[208 170  96]\n",
            "  [201 153  34]\n",
            "  [198 161  26]\n",
            "  ...\n",
            "  [160 133  70]\n",
            "  [ 56  31   7]\n",
            "  [ 53  34  20]]\n",
            "\n",
            " [[180 139  96]\n",
            "  [173 123  42]\n",
            "  [186 144  30]\n",
            "  ...\n",
            "  [184 148  94]\n",
            "  [ 97  62  34]\n",
            "  [ 83  53  34]]\n",
            "\n",
            " [[177 144 116]\n",
            "  [168 129  94]\n",
            "  [179 142  87]\n",
            "  ...\n",
            "  [216 184 140]\n",
            "  [151 118  84]\n",
            "  [123  92  72]]]\n"
          ]
        }
      ],
      "source": [
        "print(x_train[0])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ulT9Dk-gc9v2"
      },
      "source": [
        "In order to see the image as an image rather than a series of pixel value numbers, we will use a function from matplotlib:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "aSg5Kn_5c9v3"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 430
        },
        "id": "mhDiSAq3c9v3",
        "outputId": "56d626fc-4adb-4741-c3c8-76ba741b67ec"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "img = plt.imshow(x_train[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8hPCM2pPc9v3",
        "outputId": "87212087-edf3-4d82-9a8c-eadd6a859fac"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The label is: [6]\n"
          ]
        }
      ],
      "source": [
        "print('The label is:', y_train[0])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DVG0DJBMc9v3"
      },
      "source": [
        "Let's explore one more image, the second image (with index 1 instead of 0) in our training dataset:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 430
        },
        "id": "biRP1AqTc9v3",
        "outputId": "57dbce7c-91e9-4786-f5b3-8d958341d7ba"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "img = plt.imshow(x_train[1])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cbSAqLSrc9v3",
        "outputId": "a019938c-e382-44e0-faa6-e403994f313d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The label is: [9]\n"
          ]
        }
      ],
      "source": [
        "print('The label is:', y_train[1])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EtJA7eagc9v3"
      },
      "source": [
        "What we really want is the probability of each of the 10 different classes. For that, we need 10 output neurons in our neural network. Since we have 10 output neurons, our labels must match this as well. To do this, we convert the label into a set of 10 numbers where each number represents if the image belongs to that class or not. So if an image belongs to the first class, the first number of this set will be a 1 and all other numbers in this set will be a 0. To convert our labels to our one-hot encoding, we use a function in Keras:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "hRKG2Sgec9v3"
      },
      "outputs": [],
      "source": [
        "import keras\n",
        "y_train_one_hot = keras.utils.to_categorical(y_train, 10)\n",
        "y_test_one_hot = keras.utils.to_categorical(y_test, 10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JSaNXJ54c9v4",
        "outputId": "9dfe4bfd-4af4-4438-b331-65aae6a7d4a0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The one hot label is: [0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n"
          ]
        }
      ],
      "source": [
        "print('The one hot label is:', y_train_one_hot[1])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LohYsdb3c9v4"
      },
      "source": [
        "A common step we do is to let the values to be between 0 and 1, which will aid in the training of our neural network. Since our pixel values already take the values between 0 and 255, we simply need to divide by 255."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "gG4UuCnic9v4"
      },
      "outputs": [],
      "source": [
        "x_train = x_train.astype('float32')\n",
        "x_test = x_test.astype('float32')\n",
        "x_train = x_train / 255\n",
        "x_test = x_test / 255"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4KQUrxz8c9v4",
        "outputId": "7303f3e0-25d2-4e55-a0d2-c2782fdb86b7"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[[0.23137255, 0.24313726, 0.24705882],\n",
              "        [0.16862746, 0.18039216, 0.1764706 ],\n",
              "        [0.19607843, 0.1882353 , 0.16862746],\n",
              "        ...,\n",
              "        [0.61960787, 0.5176471 , 0.42352942],\n",
              "        [0.59607846, 0.49019608, 0.4       ],\n",
              "        [0.5803922 , 0.4862745 , 0.40392157]],\n",
              "\n",
              "       [[0.0627451 , 0.07843138, 0.07843138],\n",
              "        [0.        , 0.        , 0.        ],\n",
              "        [0.07058824, 0.03137255, 0.        ],\n",
              "        ...,\n",
              "        [0.48235294, 0.34509805, 0.21568628],\n",
              "        [0.46666667, 0.3254902 , 0.19607843],\n",
              "        [0.47843137, 0.34117648, 0.22352941]],\n",
              "\n",
              "       [[0.09803922, 0.09411765, 0.08235294],\n",
              "        [0.0627451 , 0.02745098, 0.        ],\n",
              "        [0.19215687, 0.10588235, 0.03137255],\n",
              "        ...,\n",
              "        [0.4627451 , 0.32941177, 0.19607843],\n",
              "        [0.47058824, 0.32941177, 0.19607843],\n",
              "        [0.42745098, 0.28627452, 0.16470589]],\n",
              "\n",
              "       ...,\n",
              "\n",
              "       [[0.8156863 , 0.6666667 , 0.3764706 ],\n",
              "        [0.7882353 , 0.6       , 0.13333334],\n",
              "        [0.7764706 , 0.6313726 , 0.10196079],\n",
              "        ...,\n",
              "        [0.627451  , 0.52156866, 0.27450982],\n",
              "        [0.21960784, 0.12156863, 0.02745098],\n",
              "        [0.20784314, 0.13333334, 0.07843138]],\n",
              "\n",
              "       [[0.7058824 , 0.54509807, 0.3764706 ],\n",
              "        [0.6784314 , 0.48235294, 0.16470589],\n",
              "        [0.7294118 , 0.5647059 , 0.11764706],\n",
              "        ...,\n",
              "        [0.72156864, 0.5803922 , 0.36862746],\n",
              "        [0.38039216, 0.24313726, 0.13333334],\n",
              "        [0.3254902 , 0.20784314, 0.13333334]],\n",
              "\n",
              "       [[0.69411767, 0.5647059 , 0.45490196],\n",
              "        [0.65882355, 0.5058824 , 0.36862746],\n",
              "        [0.7019608 , 0.5568628 , 0.34117648],\n",
              "        ...,\n",
              "        [0.84705883, 0.72156864, 0.54901963],\n",
              "        [0.5921569 , 0.4627451 , 0.32941177],\n",
              "        [0.48235294, 0.36078432, 0.28235295]]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ],
      "source": [
        "x_train[0]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jkU9ss01c9v4"
      },
      "source": [
        "# Building and Training our Convolutional Neural Network"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rBhC8Johc9v4"
      },
      "source": [
        "Similar to our first notebook, we need to define the architecture (template) first before fitting the best numbers into this architecture by learning from the data. In summary, the architecture we will build in this post is this:\n",
        "\n",
        "- Conv Layer (Filter size 3x3, Depth 32)\n",
        "- Conv Layer (Filter size 3x3, Depth 32)\n",
        "- Max Pool Layer (Filter size 2x2)\n",
        "- Dropout Layer (Prob of dropout 0.25)\n",
        "- Conv Layer (Filter size 3x3, Depth 64)\n",
        "- Conv Layer (Filter size 3x3, Depth 64)\n",
        "- Max Pool Layer (Filter size 2x2)\n",
        "- Dropout Layer (Prob of dropout 0.25)\n",
        "- FC Layer (512 neurons)\n",
        "- Dropout Layer (Prob of dropout 0.5)\n",
        "- FC Layer, Softmax (10 neurons)\n",
        "\n",
        "For an intuition behind these layers, please refer to Intuitive Deep Learning [Part 2](https://medium.com/intuitive-deep-learning/intuitive-deep-learning-part-2-cnns-for-computer-vision-24992d050a27).\n",
        "\n",
        "We will be using Keras to build our architecture. Let's import the code from Keras that we will need to use:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "j0iLaRKtc9v4"
      },
      "outputs": [],
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPooling2D"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ceaFak8cc9v4"
      },
      "source": [
        "We then call an empty Sequential model and 'add' to this model layer by layer:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "5HHuKrDac9v4"
      },
      "outputs": [],
      "source": [
        "model = Sequential()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rRho7I6Kc9v5"
      },
      "source": [
        "The first layer is a conv layer with filter size 3x3, stride size 1 (in both dimensions), and depth 32. The padding is the 'same' and the activation is 'relu' (these two settings will apply to all layers in our CNN). We add this layer to our empty sequential model using the function model.add().\n",
        "\n",
        "The first number 32 refers to the depth. The next pair of numbers (3,3) refer to the filter width and size. Then, we specify activation which is 'relu' and padding which is 'same'. Notice that we did not specify stride. This is because stride=1 is a default setting, and unless we want to change this setting, we need not specify it.\n",
        "\n",
        "If you recall, we also need to specify an input size for our first layer; subsequent layers does not have this specification since they can infer the input size from the output size of the previous layer.\n",
        "\n",
        "All that being said, our first layer in code looks like this:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OeT29-Xrc9v5",
        "outputId": "fd38e417-c251-40e2-a1c6-448c6d563a67"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        }
      ],
      "source": [
        "model.add(Conv2D(32, (3, 3), activation='relu', padding='same', input_shape=(32,32,3)))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OgNuZpySc9v5"
      },
      "source": [
        "Our second layer looks like this in code (we don't need to specify the input size):"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "SRphnFiIc9v5"
      },
      "outputs": [],
      "source": [
        "model.add(Conv2D(32, (3, 3), activation='relu', padding='same'))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JVBQPZ4tc9v5"
      },
      "source": [
        "The next layer is a max pooling layer with pool size 2 x 2 and stride 2 (in both dimensions). The default for a max pooling layer stride is the pool size, so we don't have to specify the stride:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "_bvcngTUc9v5"
      },
      "outputs": [],
      "source": [
        "model.add(MaxPooling2D(pool_size=(2, 2)))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y3O4z7Ccc9v5"
      },
      "source": [
        "Lastly, we add a dropout layer with probability 0.25 of dropout so as to prevent overfitting:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "cV8dklftc9v5"
      },
      "outputs": [],
      "source": [
        "model.add(Dropout(0.25))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BkRBwAaYc9v5"
      },
      "source": [
        "And there we have it, our first four layers in code. The next four layers look really similar (except the depth of the conv layer is 64 instead of 32):"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "5_tSc3hpc9v5"
      },
      "outputs": [],
      "source": [
        "model.add(Conv2D(64, (3, 3), activation='relu', padding='same'))\n",
        "model.add(Conv2D(64, (3, 3), activation='relu', padding='same'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(Dropout(0.25))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q9WyXqekc9v5"
      },
      "source": [
        "Lastly, we have to code in our fully connected layer, which is similar to what we've done in our previous post, [Build your first Neural Network](https://medium.com/intuitive-deep-learning/build-your-first-neural-network-to-predict-house-prices-with-keras-eb5db60232c). However, at this point, our neurons are spatially arranged in a cube-like format rather than in just one row. To make this cube-like format of neurons into one row, we have to first flatten it. We do so by adding a Flatten layer:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "_o_4aIUDc9v5"
      },
      "outputs": [],
      "source": [
        "model.add(Flatten())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FtUKR-VWc9v9"
      },
      "source": [
        "Now, we have a dense (FC) layer of 512 neurons with relu activation:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "bvZ1chJyc9v9"
      },
      "outputs": [],
      "source": [
        "model.add(Dense(512, activation='relu'))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q-oF9hv5c9v9"
      },
      "source": [
        "We add another dropout of probability 0.5:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "7rFV3vXZc9v-"
      },
      "outputs": [],
      "source": [
        "model.add(Dropout(0.5))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GMtyx9c4c9v-"
      },
      "source": [
        "And lastly, we have a dense (FC) layer with 10 neurons and softmax activation:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "TVTC-aVVc9v-"
      },
      "outputs": [],
      "source": [
        "model.add(Dense(10, activation='softmax'))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1qQJTP5tc9v-"
      },
      "source": [
        "And we're done with specifying our architecture! To see a summary of the full architecture, we run the code:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 544
        },
        "id": "UV8LSxkIc9v-",
        "outputId": "7c4e726e-8920-404b-9638-3974c0bcd628"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"sequential\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ conv2d (\u001b[38;5;33mConv2D\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m)     │           \u001b[38;5;34m896\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv2d_1 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m)     │         \u001b[38;5;34m9,248\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ max_pooling2d (\u001b[38;5;33mMaxPooling2D\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m32\u001b[0m)     │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout (\u001b[38;5;33mDropout\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m32\u001b[0m)     │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv2d_2 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │        \u001b[38;5;34m18,496\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv2d_3 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │        \u001b[38;5;34m36,928\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ max_pooling2d_1 (\u001b[38;5;33mMaxPooling2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m64\u001b[0m)       │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_1 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m64\u001b[0m)       │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ flatten (\u001b[38;5;33mFlatten\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4096\u001b[0m)           │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)            │     \u001b[38;5;34m2,097,664\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_2 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m)             │         \u001b[38;5;34m5,130\u001b[0m │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ conv2d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)     │           <span style=\"color: #00af00; text-decoration-color: #00af00\">896</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv2d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)     │         <span style=\"color: #00af00; text-decoration-color: #00af00\">9,248</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ max_pooling2d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)     │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)     │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv2d_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │        <span style=\"color: #00af00; text-decoration-color: #00af00\">18,496</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv2d_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │        <span style=\"color: #00af00; text-decoration-color: #00af00\">36,928</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ max_pooling2d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)       │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)       │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ flatten (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4096</span>)           │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)            │     <span style=\"color: #00af00; text-decoration-color: #00af00\">2,097,664</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">5,130</span> │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m2,168,362\u001b[0m (8.27 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,168,362</span> (8.27 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m2,168,362\u001b[0m (8.27 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,168,362</span> (8.27 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "model.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "39vvBikAc9v-"
      },
      "source": [
        "We now fill in the best numbers after we've specified our architecture. We'll compile the model with our settings below.\n",
        "\n",
        "The loss function we use is called categorical cross entropy, which is applicable for a classification problem of many classes. The optimizer we use here is Adam. We haven't gone through the intuition of Adam yet, but know that Adam is simply a type of stochastic gradient descent (with a few modifications) so that it trains better. Lastly, we want to track the accuracy of our model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "Lrw8iaoic9v-"
      },
      "outputs": [],
      "source": [
        "model.compile(loss='categorical_crossentropy',\n",
        "              optimizer='adam',\n",
        "              metrics=['accuracy'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wa1GNN5mc9v-"
      },
      "source": [
        "And now, it's time to run our training.\n",
        "\n",
        "We train our model with batch size 32 and 20 epochs. We use the setting validation_split=0.2 instead of validation_data. With this shortcut, we did not need to split our dataset into a train and validation set at the start! Instead, we simply specify how much of our dataset will be used as a validation set. In this case, 20% of our dataset is used as a validation set. This will take a while on a CPU, so you might want to start training and get some coffee before coming back."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 356
        },
        "id": "oh99gjZAc9v-",
        "outputId": "8eb8abe2-61e2-46d6-ccdf-61965bd59965"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "\u001b[1m  30/1250\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3:33\u001b[0m 175ms/step - accuracy: 0.8318 - loss: 0.5140"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-3133994329.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m hist = model.fit(x_train, y_train_one_hot,\n\u001b[0m\u001b[1;32m      2\u001b[0m            \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m            validation_split=0.2)\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/keras/src/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    115\u001b[0m         \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 117\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    118\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    119\u001b[0m             \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/keras/src/backend/tensorflow/trainer.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq)\u001b[0m\n\u001b[1;32m    369\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0mstep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miterator\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mepoch_iterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    370\u001b[0m                     \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 371\u001b[0;31m                     \u001b[0mlogs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    372\u001b[0m                     \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    373\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstop_training\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/keras/src/backend/tensorflow/trainer.py\u001b[0m in \u001b[0;36mfunction\u001b[0;34m(iterator)\u001b[0m\n\u001b[1;32m    217\u001b[0m                 \u001b[0miterator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdistribute\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDistributedIterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    218\u001b[0m             ):\n\u001b[0;32m--> 219\u001b[0;31m                 \u001b[0mopt_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmulti_step_on_iterator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    220\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mopt_outputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhas_value\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    221\u001b[0m                     \u001b[0;32mraise\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    831\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    832\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 833\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    834\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    835\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    876\u001b[0m       \u001b[0;31m# In this case we have not created variables on the first call. So we can\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    877\u001b[0m       \u001b[0;31m# run the first trace but we should fail if variables are created.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 878\u001b[0;31m       results = tracing_compilation.call_function(\n\u001b[0m\u001b[1;32m    879\u001b[0m           \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_variable_creation_config\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    880\u001b[0m       )\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/eager/polymorphic_function/tracing_compilation.py\u001b[0m in \u001b[0;36mcall_function\u001b[0;34m(args, kwargs, tracing_options)\u001b[0m\n\u001b[1;32m    137\u001b[0m   \u001b[0mbound_args\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    138\u001b[0m   \u001b[0mflat_inputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munpack_inputs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbound_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 139\u001b[0;31m   return function._call_flat(  # pylint: disable=protected-access\n\u001b[0m\u001b[1;32m    140\u001b[0m       \u001b[0mflat_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfunction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    141\u001b[0m   )\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/eager/polymorphic_function/concrete_function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, tensor_inputs, captured_inputs)\u001b[0m\n\u001b[1;32m   1320\u001b[0m         and executing_eagerly):\n\u001b[1;32m   1321\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1322\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_inference_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall_preflattened\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1323\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1324\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py\u001b[0m in \u001b[0;36mcall_preflattened\u001b[0;34m(self, args)\u001b[0m\n\u001b[1;32m    214\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mcall_preflattened\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mSequence\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    215\u001b[0m     \u001b[0;34m\"\"\"Calls with flattened tensor inputs and returns the structured output.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 216\u001b[0;31m     \u001b[0mflat_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall_flat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    217\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpack_output\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mflat_outputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    218\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py\u001b[0m in \u001b[0;36mcall_flat\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m    249\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mrecord\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstop_recording\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    250\u001b[0m           \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_bound_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecuting_eagerly\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 251\u001b[0;31m             outputs = self._bound_context.call_function(\n\u001b[0m\u001b[1;32m    252\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    253\u001b[0m                 \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/eager/context.py\u001b[0m in \u001b[0;36mcall_function\u001b[0;34m(self, name, tensor_inputs, num_outputs)\u001b[0m\n\u001b[1;32m   1681\u001b[0m     \u001b[0mcancellation_context\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcancellation\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1682\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcancellation_context\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1683\u001b[0;31m       outputs = execute.execute(\n\u001b[0m\u001b[1;32m   1684\u001b[0m           \u001b[0mname\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"utf-8\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1685\u001b[0m           \u001b[0mnum_outputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnum_outputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     51\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 53\u001b[0;31m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[1;32m     54\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[1;32m     55\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "hist = model.fit(x_train, y_train_one_hot,\n",
        "           batch_size=32, epochs=20,\n",
        "           validation_split=0.2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VfaWBUh4c9v-"
      },
      "source": [
        "After you've done training, we can visualize the model training and validation loss as well as training / validation accuracy over the number of epochs using the below code:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        },
        "id": "KOfJBowBc9v_",
        "outputId": "0e184aad-78a5-4a23-b3e2-e29c45c8d5d7"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'hist' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-3009041320.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhist\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'loss'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhist\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'val_loss'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtitle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Model loss'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mylabel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Loss'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mxlabel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Epoch'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'hist' is not defined"
          ]
        }
      ],
      "source": [
        "plt.plot(hist.history['loss'])\n",
        "plt.plot(hist.history['val_loss'])\n",
        "plt.title('Model loss')\n",
        "plt.ylabel('Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend(['Train', 'Val'], loc='upper right')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uMKWUFKRc9v_"
      },
      "outputs": [],
      "source": [
        "plt.plot(hist.history['acc'])\n",
        "plt.plot(hist.history['val_acc'])\n",
        "plt.title('Model accuracy')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend(['Train', 'Val'], loc='lower right')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zzkFZJGTc9v_"
      },
      "source": [
        "Once we are done with tweaking our hyperparameters, we can run it on our test dataset below:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vSJrpZtqc9v_"
      },
      "outputs": [],
      "source": [
        "model.evaluate(x_test, y_test_one_hot)[1]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tuTDJM5lc9v_"
      },
      "source": [
        "At this point, you might want to save your trained model (since you've spent so long waiting for it to train). The model will be saved in a file format called HDF5 (with the extension .h5). We save our model with this line of code:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QonUgleYc9v_"
      },
      "outputs": [],
      "source": [
        "model.save('my_cifar10_model.h5')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Mgr_4hujc9v_"
      },
      "source": [
        "# Testing out with your own images"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L9fMyuujc9v_"
      },
      "source": [
        "Now that we have a model, let's try it on our own images. To do so, place your image in the same directory as your notebook. For the purposes of this post, I'm going to use an image of a cat (which you can download here(link)). Now, we read in our JPEG file as an array of pixel values:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bmPgeVk5c9v_"
      },
      "outputs": [],
      "source": [
        "my_image = plt.imread(\"cat.jpg\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tphF7argc9wA"
      },
      "source": [
        "The first thing we have to do is to resize the image of our cat so that we can fit it into our model (input size of 32 * 32 * 3)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "s7EushKsc9wA"
      },
      "outputs": [],
      "source": [
        "from skimage.transform import resize\n",
        "my_image_resized = resize(my_image, (32,32,3))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "m1fxpuuKc9wA"
      },
      "outputs": [],
      "source": [
        "img = plt.imshow(my_image_resized)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jIRPjeOZc9wA"
      },
      "source": [
        "And now, we see what our trained model will output when given an image of our cat, using this code:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "X4f3KLGmc9wA"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "probabilities = model.predict(np.array( [my_image_resized,] ))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "or2xJ95sc9wA"
      },
      "outputs": [],
      "source": [
        "probabilities"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_H3Pwo5oc9wA"
      },
      "outputs": [],
      "source": [
        "number_to_class = ['airplane', 'automobile', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck']\n",
        "index = np.argsort(probabilities[0,:])\n",
        "print(\"Most likely class:\", number_to_class[index[9]], \"-- Probability:\", probabilities[0,index[9]])\n",
        "print(\"Second most likely class:\", number_to_class[index[8]], \"-- Probability:\", probabilities[0,index[8]])\n",
        "print(\"Third most likely class:\", number_to_class[index[7]], \"-- Probability:\", probabilities[0,index[7]])\n",
        "print(\"Fourth most likely class:\", number_to_class[index[6]], \"-- Probability:\", probabilities[0,index[6]])\n",
        "print(\"Fifth most likely class:\", number_to_class[index[5]], \"-- Probability:\", probabilities[0,index[5]])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iivbxkOic9wA"
      },
      "source": [
        "As you can see, the model has accurately predicted that this is indeed an image of a cat. Now, this isn't the best model we have and accuracy has been quite low, so don't expect too much out of it. This post has covered the very fundamentals of CNNs on a very simple dataset; we'll cover how to build state-of-the-art models in future posts. Nevertheless, you should be able to get some pretty cool results from your own images (some images that you can try this out on are in the GitHub folder)."
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.8"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}